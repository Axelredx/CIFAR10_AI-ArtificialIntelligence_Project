{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbHgg5ORahnB"
   },
   "source": [
    "# CIFAR-10 Image Separation Model\n",
    "Progetto svolto da Alex Rossi 0001089916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4N7MfxqPZGT7"
   },
   "outputs": [],
   "source": [
    "# import vari\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwbQ3bjtelbu"
   },
   "source": [
    "## Caricamento e Preprocessing dati\n",
    "(Già forniti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zWfMPfEbS6j",
    "outputId": "736277cc-89e2-435b-ea7c-744f4ed85bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar10.load_data()\n",
    "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
    "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
    "assert cifar10_y_train.shape == (50000, 1)\n",
    "assert cifar10_y_test.shape == (10000, 1)\n",
    "\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
    "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)\n",
    "\n",
    "# Separazione delle immagini in due gruppi in base alla loro etichetta\n",
    "cond_1 = cifar10_y_train[:,0] < 5\n",
    "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
    "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
    "\n",
    "cond_2 = cifar10_y_train[:,0] >= 5\n",
    "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
    "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
    "\n",
    "cond_1_test = cifar10_y_test[:,0] < 5\n",
    "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
    "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
    "\n",
    "cond_2_test = cifar10_y_test[:,0] >= 5\n",
    "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
    "cifar10_y_test_2 = cifar10_y_test[cond_2_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgtQofume1TA"
   },
   "source": [
    "### Definizione generatore immagini\n",
    "(**Nota**: una parte del formato dei dati è stato cambiato ai fini di rendere il tutto compatibile con il modello creato, in modo tale da non restituire errori durante la fase di training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mKe--F_Se7ne"
   },
   "outputs": [],
   "source": [
    "def datagenerator(X1, X2, Y1, Y2, batchsize):\n",
    "    size1 = X1.shape[0]\n",
    "    size2 = X2.shape[0]\n",
    "    Y1_cat = tf.keras.utils.to_categorical(Y1, num_classes=5)\n",
    "    Y2_cat = tf.keras.utils.to_categorical(Y2-5, num_classes=5)\n",
    "\n",
    "    while True:\n",
    "        num1 = np.random.randint(0, size1, batchsize)\n",
    "        num2 = np.random.randint(0, size2, batchsize)\n",
    "        x_data = (X1[num1] + X2[num2]) / 2.0\n",
    "        y_data = (Y1_cat[num1], Y2_cat[num2])  # Usa una tupla invece di una lista\n",
    "\n",
    "        yield x_data, y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttad8YuigITA"
   },
   "source": [
    "## Definizione del Modello predittorio\n",
    "Per il problema proposto si è scelto l'uso di una **CNN**, (rete convoluzionale).\n",
    "Si è optato per un modello CNN poichè il loro uso è tipico nei problemi di riconoscimento di immagini (Image Classification & Detection).  \n",
    "Nella creazione del modello ci si è ispirati all'architettura di uno dei più famosi, _AlexNet_ (Uso di _layer convoluzionali_ seguiti da _normalizzazioni_ e _pooling_, _dropout_ dopo _layer densi_, etc...), ma facendo aggiunte come il _calcolo residuale_.\n",
    "\n",
    "Aspetti interessanti implementati nel modello:\n",
    "- Vari **blocchi convuluzioniali** con **periodiche normalizzazioni** (contrastare oerfitting);\n",
    "- Uso della tecnica del **calcolo residuale** (in questa versione, rispetto ad un precedente modello implementato in cui non era presente, si ha un incremento dell'accurancy e diminuzione della loss di almeno il 10%);\n",
    "- Uso di **GlobalAveragePooling()** invece di **Flatten()** per il passaggio da vettore multidimensionale a monodimensionale;\n",
    "- **Layer di Dropout**: tecnica di regolarizzazione utilizzata nelle reti neurali per ridurre l'overfitting (e quindi evitare che il modello si adatti troppo ai dati di allenamento e perda la capacità di generalizzare su nuovi dati);\n",
    "- Uso dell'optimizer **Adam**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "23R4OmoRU4pb",
    "outputId": "a38a288e-b771-468e-9c47-5efad73c9bd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ max_pooling2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│                           │                        │                │ max_pooling2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ global_average_poolin… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m896\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ max_pooling2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│                           │                        │                │ max_pooling2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m33,024\u001b[0m │ global_average_poolin… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │          \u001b[38;5;34m1,285\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output_2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │          \u001b[38;5;34m1,285\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">277,834</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m277,834\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">277,130</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m277,130\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "def create_cifar10_model():\n",
    "    input_layer = layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "    # Blocchi convoluzionali\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x) #batch normalization\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Residual Connection\n",
    "    residual = x\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, residual])\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x) # al posto di Flatten()\n",
    "\n",
    "    # Dense layers con dropout\n",
    "    dense_shared = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    dense_shared = layers.Dropout(0.5)(dense_shared)\n",
    "\n",
    "    output_1 = layers.Dense(5, activation='softmax', name=\"output_1\")(dense_shared)\n",
    "    output_2 = layers.Dense(5, activation='softmax', name=\"output_2\")(dense_shared)\n",
    "\n",
    "    # Creazione del modello\n",
    "    model = Model(inputs=input_layer, outputs=[output_1, output_2])\n",
    "\n",
    "    # Compilazione con learning rate scheduling\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "                  metrics=['accuracy', 'accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_cifar10_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfPeACFMmc1s"
   },
   "source": [
    "## Training modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzhwBdW1cTLd",
    "outputId": "944be428-2e47-418d-891d-97f7d663fe50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: (64, 32, 32, 3)\n",
      "y_batch[0] shape: (64, 5)\n",
      "y_batch[1] shape: (64, 5)\n"
     ]
    }
   ],
   "source": [
    "# Mini test modello\n",
    "datagen_train = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batchsize=64)\n",
    "x_batch, y_batch = next(datagen_train)\n",
    "\n",
    "print(\"x_batch shape:\", x_batch.shape)  # Dovrebbe essere (64, 32, 32, 3)\n",
    "print(\"y_batch[0] shape:\", y_batch[0].shape)  # Dovrebbe essere (64, 5)\n",
    "print(\"y_batch[1] shape:\", y_batch[1].shape)  # Dovrebbe essere (64, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw6i6nSe5H-4"
   },
   "source": [
    "Per cercare di contrastare l'overfitting, si usufruisce di un meccanismo di **early stopping**: si tiene sotto controllo la _loss_ e se dopo _3 epoche_ consecutive non vi è miglioramento, e quindi non c'è un apprendimento da parte del modello, fermo il training stesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4QBHoBs_muGT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pnk3muN7fwY"
   },
   "source": [
    "Salvo i progressi del modello tramite **checkpoint** tenendo traccia della _loss_: se vi è una diminuzione rispetto all'epoca precedente, salvo i progressi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Ffk-lxF07d9P"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model_checkpoint.keras',\n",
    "    monitor='loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primo training: inizio con una batch_size 'piccola' per poi anando ad aumentare durante le altre fasi di training del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpgHxukWTwr8",
    "outputId": "00a3b77e-e2df-4d58-e288-c40db464e3ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 998/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5487 - output_1_accuracy: 0.4056 - output_1_loss: 1.4038 - output_2_accuracy: 0.4684 - output_2_loss: 1.3100\n",
      "Epoch 1: loss improved from inf to 2.91562, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 3.5468 - output_1_accuracy: 0.4058 - output_1_loss: 1.4035 - output_2_accuracy: 0.4686 - output_2_loss: 1.3096\n",
      "Epoch 2/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2425 - output_1_accuracy: 0.5131 - output_1_loss: 1.1891 - output_2_accuracy: 0.6231 - output_2_loss: 0.9788\n",
      "Epoch 2: loss improved from 2.91562 to 2.18638, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 2.2422 - output_1_accuracy: 0.5132 - output_1_loss: 1.1889 - output_2_accuracy: 0.6232 - output_2_loss: 0.9787\n",
      "Epoch 3/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0498 - output_1_accuracy: 0.5576 - output_1_loss: 1.0979 - output_2_accuracy: 0.6673 - output_2_loss: 0.8798\n",
      "Epoch 3: loss improved from 2.18638 to 2.01893, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 2.0496 - output_1_accuracy: 0.5576 - output_1_loss: 1.0978 - output_2_accuracy: 0.6673 - output_2_loss: 0.8797\n",
      "Epoch 4/100\n",
      "\u001b[1m 994/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9526 - output_1_accuracy: 0.5810 - output_1_loss: 1.0498 - output_2_accuracy: 0.6907 - output_2_loss: 0.8285\n",
      "Epoch 4: loss improved from 2.01893 to 1.93242, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.9525 - output_1_accuracy: 0.5811 - output_1_loss: 1.0497 - output_2_accuracy: 0.6908 - output_2_loss: 0.8284\n",
      "Epoch 5/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8788 - output_1_accuracy: 0.6007 - output_1_loss: 1.0119 - output_2_accuracy: 0.7095 - output_2_loss: 0.7906\n",
      "Epoch 5: loss improved from 1.93242 to 1.86065, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.8787 - output_1_accuracy: 0.6007 - output_1_loss: 1.0118 - output_2_accuracy: 0.7095 - output_2_loss: 0.7905\n",
      "Epoch 6/100\n",
      "\u001b[1m 992/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8241 - output_1_accuracy: 0.6142 - output_1_loss: 0.9857 - output_2_accuracy: 0.7220 - output_2_loss: 0.7601\n",
      "Epoch 6: loss improved from 1.86065 to 1.80967, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.8240 - output_1_accuracy: 0.6142 - output_1_loss: 0.9856 - output_2_accuracy: 0.7220 - output_2_loss: 0.7600\n",
      "Epoch 7/100\n",
      "\u001b[1m 994/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7700 - output_1_accuracy: 0.6251 - output_1_loss: 0.9590 - output_2_accuracy: 0.7320 - output_2_loss: 0.7319\n",
      "Epoch 7: loss improved from 1.80967 to 1.76249, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.7699 - output_1_accuracy: 0.6251 - output_1_loss: 0.9590 - output_2_accuracy: 0.7320 - output_2_loss: 0.7319\n",
      "Epoch 8/100\n",
      "\u001b[1m 992/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7291 - output_1_accuracy: 0.6335 - output_1_loss: 0.9338 - output_2_accuracy: 0.7365 - output_2_loss: 0.7144\n",
      "Epoch 8: loss improved from 1.76249 to 1.71647, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.7290 - output_1_accuracy: 0.6336 - output_1_loss: 0.9338 - output_2_accuracy: 0.7365 - output_2_loss: 0.7143\n",
      "Epoch 9/100\n",
      "\u001b[1m 993/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7041 - output_1_accuracy: 0.6415 - output_1_loss: 0.9197 - output_2_accuracy: 0.7397 - output_2_loss: 0.7021\n",
      "Epoch 9: loss improved from 1.71647 to 1.69074, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.7040 - output_1_accuracy: 0.6416 - output_1_loss: 0.9196 - output_2_accuracy: 0.7398 - output_2_loss: 0.7020\n",
      "Epoch 10/100\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6791 - output_1_accuracy: 0.6466 - output_1_loss: 0.9136 - output_2_accuracy: 0.7486 - output_2_loss: 0.6828\n",
      "Epoch 10: loss improved from 1.69074 to 1.66524, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.6791 - output_1_accuracy: 0.6466 - output_1_loss: 0.9136 - output_2_accuracy: 0.7486 - output_2_loss: 0.6828\n",
      "Epoch 11/100\n",
      "\u001b[1m 997/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6509 - output_1_accuracy: 0.6535 - output_1_loss: 0.8937 - output_2_accuracy: 0.7519 - output_2_loss: 0.6741\n",
      "Epoch 11: loss improved from 1.66524 to 1.64493, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.6508 - output_1_accuracy: 0.6535 - output_1_loss: 0.8937 - output_2_accuracy: 0.7519 - output_2_loss: 0.6740\n",
      "Epoch 12/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6234 - output_1_accuracy: 0.6588 - output_1_loss: 0.8851 - output_2_accuracy: 0.7621 - output_2_loss: 0.6537\n",
      "Epoch 12: loss improved from 1.64493 to 1.62188, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.6234 - output_1_accuracy: 0.6588 - output_1_loss: 0.8851 - output_2_accuracy: 0.7621 - output_2_loss: 0.6537\n",
      "Epoch 13/100\n",
      "\u001b[1m 997/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5993 - output_1_accuracy: 0.6665 - output_1_loss: 0.8652 - output_2_accuracy: 0.7626 - output_2_loss: 0.6487\n",
      "Epoch 13: loss improved from 1.62188 to 1.59859, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.5993 - output_1_accuracy: 0.6665 - output_1_loss: 0.8652 - output_2_accuracy: 0.7626 - output_2_loss: 0.6487\n",
      "Epoch 14/100\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5937 - output_1_accuracy: 0.6675 - output_1_loss: 0.8566 - output_2_accuracy: 0.7651 - output_2_loss: 0.6503\n",
      "Epoch 14: loss improved from 1.59859 to 1.59449, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.5937 - output_1_accuracy: 0.6675 - output_1_loss: 0.8566 - output_2_accuracy: 0.7651 - output_2_loss: 0.6503\n",
      "Epoch 15/100\n",
      "\u001b[1m 998/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5714 - output_1_accuracy: 0.6733 - output_1_loss: 0.8484 - output_2_accuracy: 0.7674 - output_2_loss: 0.6356\n",
      "Epoch 15: loss improved from 1.59449 to 1.56406, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.5714 - output_1_accuracy: 0.6733 - output_1_loss: 0.8483 - output_2_accuracy: 0.7674 - output_2_loss: 0.6356\n",
      "Epoch 16/100\n",
      "\u001b[1m 996/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5625 - output_1_accuracy: 0.6800 - output_1_loss: 0.8402 - output_2_accuracy: 0.7697 - output_2_loss: 0.6347\n",
      "Epoch 16: loss improved from 1.56406 to 1.56004, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.5625 - output_1_accuracy: 0.6800 - output_1_loss: 0.8402 - output_2_accuracy: 0.7697 - output_2_loss: 0.6347\n",
      "Epoch 17/100\n",
      "\u001b[1m 992/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5431 - output_1_accuracy: 0.6804 - output_1_loss: 0.8315 - output_2_accuracy: 0.7728 - output_2_loss: 0.6239\n",
      "Epoch 17: loss improved from 1.56004 to 1.54029, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.5431 - output_1_accuracy: 0.6805 - output_1_loss: 0.8315 - output_2_accuracy: 0.7728 - output_2_loss: 0.6239\n",
      "Epoch 18/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5365 - output_1_accuracy: 0.6788 - output_1_loss: 0.8382 - output_2_accuracy: 0.7768 - output_2_loss: 0.6098\n",
      "Epoch 18: loss improved from 1.54029 to 1.53406, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.5365 - output_1_accuracy: 0.6788 - output_1_loss: 0.8382 - output_2_accuracy: 0.7768 - output_2_loss: 0.6098\n",
      "Epoch 19/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5096 - output_1_accuracy: 0.6892 - output_1_loss: 0.8165 - output_2_accuracy: 0.7820 - output_2_loss: 0.6039\n",
      "Epoch 19: loss improved from 1.53406 to 1.51946, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.5096 - output_1_accuracy: 0.6892 - output_1_loss: 0.8165 - output_2_accuracy: 0.7820 - output_2_loss: 0.6039\n",
      "Epoch 20/100\n",
      "\u001b[1m 991/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5111 - output_1_accuracy: 0.6903 - output_1_loss: 0.8187 - output_2_accuracy: 0.7832 - output_2_loss: 0.6037\n",
      "Epoch 20: loss improved from 1.51946 to 1.51165, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.5111 - output_1_accuracy: 0.6903 - output_1_loss: 0.8187 - output_2_accuracy: 0.7832 - output_2_loss: 0.6037\n",
      "Epoch 21/100\n",
      "\u001b[1m 994/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4996 - output_1_accuracy: 0.6982 - output_1_loss: 0.8050 - output_2_accuracy: 0.7799 - output_2_loss: 0.6055\n",
      "Epoch 21: loss improved from 1.51165 to 1.50291, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.4996 - output_1_accuracy: 0.6981 - output_1_loss: 0.8051 - output_2_accuracy: 0.7800 - output_2_loss: 0.6054\n",
      "Epoch 22/100\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4878 - output_1_accuracy: 0.6924 - output_1_loss: 0.8062 - output_2_accuracy: 0.7851 - output_2_loss: 0.5917\n",
      "Epoch 22: loss improved from 1.50291 to 1.48999, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.4878 - output_1_accuracy: 0.6924 - output_1_loss: 0.8063 - output_2_accuracy: 0.7850 - output_2_loss: 0.5917\n",
      "Epoch 23/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4845 - output_1_accuracy: 0.6975 - output_1_loss: 0.7968 - output_2_accuracy: 0.7827 - output_2_loss: 0.5972\n",
      "Epoch 23: loss improved from 1.48999 to 1.48408, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.4845 - output_1_accuracy: 0.6974 - output_1_loss: 0.7968 - output_2_accuracy: 0.7827 - output_2_loss: 0.5971\n",
      "Epoch 24/100\n",
      "\u001b[1m 994/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4843 - output_1_accuracy: 0.6950 - output_1_loss: 0.8019 - output_2_accuracy: 0.7888 - output_2_loss: 0.5928\n",
      "Epoch 24: loss improved from 1.48408 to 1.47737, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.4843 - output_1_accuracy: 0.6950 - output_1_loss: 0.8019 - output_2_accuracy: 0.7888 - output_2_loss: 0.5927\n",
      "Epoch 25/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4490 - output_1_accuracy: 0.7018 - output_1_loss: 0.7832 - output_2_accuracy: 0.7942 - output_2_loss: 0.5742\n",
      "Epoch 25: loss improved from 1.47737 to 1.45895, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.4491 - output_1_accuracy: 0.7018 - output_1_loss: 0.7832 - output_2_accuracy: 0.7942 - output_2_loss: 0.5742\n",
      "Epoch 26/100\n",
      "\u001b[1m 994/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4613 - output_1_accuracy: 0.6973 - output_1_loss: 0.7867 - output_2_accuracy: 0.7900 - output_2_loss: 0.5833\n",
      "Epoch 26: loss improved from 1.45895 to 1.45492, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.4613 - output_1_accuracy: 0.6973 - output_1_loss: 0.7867 - output_2_accuracy: 0.7900 - output_2_loss: 0.5833\n",
      "Epoch 27/100\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4638 - output_1_accuracy: 0.7038 - output_1_loss: 0.7865 - output_2_accuracy: 0.7900 - output_2_loss: 0.5853\n",
      "Epoch 27: loss improved from 1.45492 to 1.45430, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.4638 - output_1_accuracy: 0.7038 - output_1_loss: 0.7865 - output_2_accuracy: 0.7900 - output_2_loss: 0.5853\n",
      "Epoch 28/100\n",
      "\u001b[1m 997/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4429 - output_1_accuracy: 0.7030 - output_1_loss: 0.7793 - output_2_accuracy: 0.7924 - output_2_loss: 0.5713\n",
      "Epoch 28: loss improved from 1.45430 to 1.44215, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.4429 - output_1_accuracy: 0.7030 - output_1_loss: 0.7794 - output_2_accuracy: 0.7924 - output_2_loss: 0.5713\n",
      "Epoch 29/100\n",
      "\u001b[1m 996/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4463 - output_1_accuracy: 0.7040 - output_1_loss: 0.7831 - output_2_accuracy: 0.7955 - output_2_loss: 0.5707\n",
      "Epoch 29: loss improved from 1.44215 to 1.43353, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.4462 - output_1_accuracy: 0.7040 - output_1_loss: 0.7831 - output_2_accuracy: 0.7955 - output_2_loss: 0.5707\n",
      "Epoch 30/100\n",
      "\u001b[1m 997/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4333 - output_1_accuracy: 0.7065 - output_1_loss: 0.7755 - output_2_accuracy: 0.7941 - output_2_loss: 0.5641\n",
      "Epoch 30: loss improved from 1.43353 to 1.42114, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.4333 - output_1_accuracy: 0.7065 - output_1_loss: 0.7754 - output_2_accuracy: 0.7941 - output_2_loss: 0.5641\n",
      "Epoch 31/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4011 - output_1_accuracy: 0.7103 - output_1_loss: 0.7598 - output_2_accuracy: 0.8024 - output_2_loss: 0.5469\n",
      "Epoch 31: loss improved from 1.42114 to 1.41360, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.4011 - output_1_accuracy: 0.7103 - output_1_loss: 0.7598 - output_2_accuracy: 0.8024 - output_2_loss: 0.5469\n",
      "Epoch 32/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4211 - output_1_accuracy: 0.7070 - output_1_loss: 0.7718 - output_2_accuracy: 0.8005 - output_2_loss: 0.5554\n",
      "Epoch 32: loss improved from 1.41360 to 1.41351, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.4210 - output_1_accuracy: 0.7070 - output_1_loss: 0.7718 - output_2_accuracy: 0.8005 - output_2_loss: 0.5554\n",
      "Epoch 33/100\n",
      "\u001b[1m 991/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4156 - output_1_accuracy: 0.7121 - output_1_loss: 0.7622 - output_2_accuracy: 0.7975 - output_2_loss: 0.5601\n",
      "Epoch 33: loss improved from 1.41351 to 1.40983, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.4156 - output_1_accuracy: 0.7121 - output_1_loss: 0.7622 - output_2_accuracy: 0.7976 - output_2_loss: 0.5600\n",
      "Epoch 34/100\n",
      "\u001b[1m 991/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4030 - output_1_accuracy: 0.7112 - output_1_loss: 0.7607 - output_2_accuracy: 0.8015 - output_2_loss: 0.5479\n",
      "Epoch 34: loss improved from 1.40983 to 1.40377, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.4030 - output_1_accuracy: 0.7112 - output_1_loss: 0.7607 - output_2_accuracy: 0.8015 - output_2_loss: 0.5479\n",
      "Epoch 35/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3947 - output_1_accuracy: 0.7124 - output_1_loss: 0.7554 - output_2_accuracy: 0.8064 - output_2_loss: 0.5446\n",
      "Epoch 35: loss improved from 1.40377 to 1.39979, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3947 - output_1_accuracy: 0.7124 - output_1_loss: 0.7554 - output_2_accuracy: 0.8064 - output_2_loss: 0.5446\n",
      "Epoch 36/100\n",
      "\u001b[1m 992/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3891 - output_1_accuracy: 0.7141 - output_1_loss: 0.7503 - output_2_accuracy: 0.8045 - output_2_loss: 0.5442\n",
      "Epoch 36: loss improved from 1.39979 to 1.38612, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.3890 - output_1_accuracy: 0.7141 - output_1_loss: 0.7503 - output_2_accuracy: 0.8045 - output_2_loss: 0.5442\n",
      "Epoch 37/100\n",
      "\u001b[1m 992/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3846 - output_1_accuracy: 0.7182 - output_1_loss: 0.7445 - output_2_accuracy: 0.8047 - output_2_loss: 0.5450\n",
      "Epoch 37: loss improved from 1.38612 to 1.38344, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3846 - output_1_accuracy: 0.7182 - output_1_loss: 0.7445 - output_2_accuracy: 0.8047 - output_2_loss: 0.5450\n",
      "Epoch 38/100\n",
      "\u001b[1m 992/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3830 - output_1_accuracy: 0.7140 - output_1_loss: 0.7525 - output_2_accuracy: 0.8089 - output_2_loss: 0.5357\n",
      "Epoch 38: loss improved from 1.38344 to 1.38188, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.3830 - output_1_accuracy: 0.7140 - output_1_loss: 0.7525 - output_2_accuracy: 0.8088 - output_2_loss: 0.5357\n",
      "Epoch 39/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3743 - output_1_accuracy: 0.7198 - output_1_loss: 0.7458 - output_2_accuracy: 0.8067 - output_2_loss: 0.5330\n",
      "Epoch 39: loss improved from 1.38188 to 1.37259, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3743 - output_1_accuracy: 0.7199 - output_1_loss: 0.7458 - output_2_accuracy: 0.8067 - output_2_loss: 0.5330\n",
      "Epoch 40/100\n",
      "\u001b[1m 992/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3753 - output_1_accuracy: 0.7218 - output_1_loss: 0.7412 - output_2_accuracy: 0.8072 - output_2_loss: 0.5391\n",
      "Epoch 40: loss did not improve from 1.37259\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3754 - output_1_accuracy: 0.7217 - output_1_loss: 0.7412 - output_2_accuracy: 0.8072 - output_2_loss: 0.5391\n",
      "Epoch 41/100\n",
      "\u001b[1m 998/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3763 - output_1_accuracy: 0.7213 - output_1_loss: 0.7408 - output_2_accuracy: 0.8078 - output_2_loss: 0.5400\n",
      "Epoch 41: loss improved from 1.37259 to 1.37021, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3763 - output_1_accuracy: 0.7213 - output_1_loss: 0.7408 - output_2_accuracy: 0.8078 - output_2_loss: 0.5400\n",
      "Epoch 42/100\n",
      "\u001b[1m 993/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3582 - output_1_accuracy: 0.7242 - output_1_loss: 0.7338 - output_2_accuracy: 0.8089 - output_2_loss: 0.5284\n",
      "Epoch 42: loss improved from 1.37021 to 1.36408, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3583 - output_1_accuracy: 0.7242 - output_1_loss: 0.7338 - output_2_accuracy: 0.8089 - output_2_loss: 0.5284\n",
      "Epoch 43/100\n",
      "\u001b[1m 991/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3710 - output_1_accuracy: 0.7242 - output_1_loss: 0.7351 - output_2_accuracy: 0.8062 - output_2_loss: 0.5399\n",
      "Epoch 43: loss did not improve from 1.36408\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.3709 - output_1_accuracy: 0.7242 - output_1_loss: 0.7351 - output_2_accuracy: 0.8062 - output_2_loss: 0.5398\n",
      "Epoch 44/100\n",
      "\u001b[1m 996/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3538 - output_1_accuracy: 0.7238 - output_1_loss: 0.7356 - output_2_accuracy: 0.8137 - output_2_loss: 0.5214\n",
      "Epoch 44: loss improved from 1.36408 to 1.35422, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3538 - output_1_accuracy: 0.7238 - output_1_loss: 0.7356 - output_2_accuracy: 0.8137 - output_2_loss: 0.5215\n",
      "Epoch 45/100\n",
      "\u001b[1m 994/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3430 - output_1_accuracy: 0.7254 - output_1_loss: 0.7267 - output_2_accuracy: 0.8125 - output_2_loss: 0.5205\n",
      "Epoch 45: loss improved from 1.35422 to 1.34576, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.3431 - output_1_accuracy: 0.7254 - output_1_loss: 0.7267 - output_2_accuracy: 0.8125 - output_2_loss: 0.5205\n",
      "Epoch 46/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3431 - output_1_accuracy: 0.7269 - output_1_loss: 0.7254 - output_2_accuracy: 0.8138 - output_2_loss: 0.5214\n",
      "Epoch 46: loss did not improve from 1.34576\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3432 - output_1_accuracy: 0.7269 - output_1_loss: 0.7255 - output_2_accuracy: 0.8138 - output_2_loss: 0.5214\n",
      "Epoch 47/100\n",
      "\u001b[1m 998/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3471 - output_1_accuracy: 0.7258 - output_1_loss: 0.7321 - output_2_accuracy: 0.8148 - output_2_loss: 0.5188\n",
      "Epoch 47: loss improved from 1.34576 to 1.34136, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3471 - output_1_accuracy: 0.7258 - output_1_loss: 0.7321 - output_2_accuracy: 0.8148 - output_2_loss: 0.5188\n",
      "Epoch 48/100\n",
      "\u001b[1m 993/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3322 - output_1_accuracy: 0.7269 - output_1_loss: 0.7217 - output_2_accuracy: 0.8146 - output_2_loss: 0.5134\n",
      "Epoch 48: loss improved from 1.34136 to 1.33341, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3322 - output_1_accuracy: 0.7269 - output_1_loss: 0.7217 - output_2_accuracy: 0.8146 - output_2_loss: 0.5134\n",
      "Epoch 49/100\n",
      "\u001b[1m 998/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3189 - output_1_accuracy: 0.7345 - output_1_loss: 0.7069 - output_2_accuracy: 0.8147 - output_2_loss: 0.5143\n",
      "Epoch 49: loss improved from 1.33341 to 1.32553, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3189 - output_1_accuracy: 0.7345 - output_1_loss: 0.7069 - output_2_accuracy: 0.8147 - output_2_loss: 0.5143\n",
      "Epoch 50/100\n",
      "\u001b[1m 994/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3333 - output_1_accuracy: 0.7248 - output_1_loss: 0.7245 - output_2_accuracy: 0.8179 - output_2_loss: 0.5117\n",
      "Epoch 50: loss did not improve from 1.32553\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3333 - output_1_accuracy: 0.7248 - output_1_loss: 0.7245 - output_2_accuracy: 0.8179 - output_2_loss: 0.5117\n",
      "Epoch 51/100\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3291 - output_1_accuracy: 0.7262 - output_1_loss: 0.7195 - output_2_accuracy: 0.8153 - output_2_loss: 0.5132\n",
      "Epoch 51: loss did not improve from 1.32553\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.3291 - output_1_accuracy: 0.7262 - output_1_loss: 0.7195 - output_2_accuracy: 0.8153 - output_2_loss: 0.5132\n",
      "Epoch 52/100\n",
      "\u001b[1m 995/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3275 - output_1_accuracy: 0.7305 - output_1_loss: 0.7138 - output_2_accuracy: 0.8159 - output_2_loss: 0.5158\n",
      "Epoch 52: loss did not improve from 1.32553\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.3276 - output_1_accuracy: 0.7305 - output_1_loss: 0.7138 - output_2_accuracy: 0.8159 - output_2_loss: 0.5158\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "datagen_train = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batchsize=batch_size)\n",
    "\n",
    "# Training del modello\n",
    "history = model.fit(\n",
    "    datagen_train,\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEkSMGDCJKUz"
   },
   "source": [
    "Si può notare come viene attuata _l'Early stopping_, ma siccome _loss_ e _accuracy degli output_ non sono ancora soddisfacenti ripeto più volte il training effettuando del tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "sf-L3_118-YR"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5ThBjEH25xE",
    "outputId": "90a0e53f-019f-4aad-f6ab-1e7d9d9d5938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1296 - output_1_accuracy: 0.7648 - output_1_loss: 0.6308 - output_2_accuracy: 0.8455 - output_2_loss: 0.4335\n",
      "Epoch 1: loss improved from 1.20950 to 1.12628, saving model to model_checkpoint.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15ms/step - loss: 1.1296 - output_1_accuracy: 0.7648 - output_1_loss: 0.6308 - output_2_accuracy: 0.8455 - output_2_loss: 0.4335\n",
      "Epoch 2/50\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1231 - output_1_accuracy: 0.7654 - output_1_loss: 0.6282 - output_2_accuracy: 0.8468 - output_2_loss: 0.4317\n",
      "Epoch 2: loss improved from 1.12628 to 1.11922, saving model to model_checkpoint.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 1.1231 - output_1_accuracy: 0.7654 - output_1_loss: 0.6282 - output_2_accuracy: 0.8468 - output_2_loss: 0.4317\n",
      "Epoch 3/50\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1140 - output_1_accuracy: 0.7668 - output_1_loss: 0.6234 - output_2_accuracy: 0.8486 - output_2_loss: 0.4261\n",
      "Epoch 3: loss improved from 1.11922 to 1.11154, saving model to model_checkpoint.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 1.1140 - output_1_accuracy: 0.7668 - output_1_loss: 0.6234 - output_2_accuracy: 0.8486 - output_2_loss: 0.4261\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_checkpoint.keras')\n",
    "batch_size = 256\n",
    "\n",
    "datagen_train = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batchsize=batch_size)\n",
    "\n",
    "# Training del modello\n",
    "history = model.fit(\n",
    "    datagen_train,\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4fsExlo6Oc-",
    "outputId": "9eb303fb-00ed-46fb-d954-25bafa05e0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0572 - output_1_accuracy: 0.7742 - output_1_loss: 0.6037 - output_2_accuracy: 0.8569 - output_2_loss: 0.4037\n",
      "Epoch 1: loss improved from 1.06794 to 1.05866, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 1.0572 - output_1_accuracy: 0.7742 - output_1_loss: 0.6037 - output_2_accuracy: 0.8569 - output_2_loss: 0.4037\n",
      "Epoch 2/50\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0544 - output_1_accuracy: 0.7757 - output_1_loss: 0.6014 - output_2_accuracy: 0.8578 - output_2_loss: 0.4015\n",
      "Epoch 2: loss improved from 1.05866 to 1.05320, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - loss: 1.0544 - output_1_accuracy: 0.7757 - output_1_loss: 0.6014 - output_2_accuracy: 0.8578 - output_2_loss: 0.4015\n",
      "Epoch 3/50\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0509 - output_1_accuracy: 0.7775 - output_1_loss: 0.5968 - output_2_accuracy: 0.8573 - output_2_loss: 0.4014\n",
      "Epoch 3: loss improved from 1.05320 to 1.04805, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - loss: 1.0509 - output_1_accuracy: 0.7775 - output_1_loss: 0.5968 - output_2_accuracy: 0.8573 - output_2_loss: 0.4014\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_checkpoint.keras')\n",
    "batch_size = 512\n",
    "\n",
    "datagen_train = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batchsize=batch_size)\n",
    "\n",
    "# Training del modello\n",
    "history = model.fit(\n",
    "    datagen_train,\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRbWqXJUGRvD",
    "outputId": "ddebdb9f-1691-4902-f73e-9b2c6ec1a2ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.0021 - output_1_accuracy: 0.7869 - output_1_loss: 0.5743 - output_2_accuracy: 0.8642 - output_2_loss: 0.3830\n",
      "Epoch 1: loss improved from 1.04805 to 0.99414, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 45ms/step - loss: 1.0021 - output_1_accuracy: 0.7869 - output_1_loss: 0.5743 - output_2_accuracy: 0.8642 - output_2_loss: 0.3830\n",
      "Epoch 2/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.9869 - output_1_accuracy: 0.7893 - output_1_loss: 0.5684 - output_2_accuracy: 0.8665 - output_2_loss: 0.3767\n",
      "Epoch 2: loss improved from 0.99414 to 0.98502, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.9869 - output_1_accuracy: 0.7893 - output_1_loss: 0.5684 - output_2_accuracy: 0.8665 - output_2_loss: 0.3767\n",
      "Epoch 3/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9845 - output_1_accuracy: 0.7895 - output_1_loss: 0.5680 - output_2_accuracy: 0.8675 - output_2_loss: 0.3735\n",
      "Epoch 3: loss improved from 0.98502 to 0.98038, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.9844 - output_1_accuracy: 0.7895 - output_1_loss: 0.5680 - output_2_accuracy: 0.8675 - output_2_loss: 0.3735\n",
      "Epoch 4/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9763 - output_1_accuracy: 0.7922 - output_1_loss: 0.5607 - output_2_accuracy: 0.8687 - output_2_loss: 0.3725\n",
      "Epoch 4: loss improved from 0.98038 to 0.97434, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.9763 - output_1_accuracy: 0.7922 - output_1_loss: 0.5607 - output_2_accuracy: 0.8687 - output_2_loss: 0.3725\n",
      "Epoch 5/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9692 - output_1_accuracy: 0.7937 - output_1_loss: 0.5572 - output_2_accuracy: 0.8695 - output_2_loss: 0.3686\n",
      "Epoch 5: loss improved from 0.97434 to 0.96688, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.9692 - output_1_accuracy: 0.7937 - output_1_loss: 0.5572 - output_2_accuracy: 0.8695 - output_2_loss: 0.3686\n",
      "Epoch 6/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9587 - output_1_accuracy: 0.7957 - output_1_loss: 0.5513 - output_2_accuracy: 0.8713 - output_2_loss: 0.3636\n",
      "Epoch 6: loss improved from 0.96688 to 0.95725, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.9587 - output_1_accuracy: 0.7957 - output_1_loss: 0.5513 - output_2_accuracy: 0.8713 - output_2_loss: 0.3636\n",
      "Epoch 7/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9527 - output_1_accuracy: 0.7973 - output_1_loss: 0.5467 - output_2_accuracy: 0.8716 - output_2_loss: 0.3621\n",
      "Epoch 7: loss improved from 0.95725 to 0.94993, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.9527 - output_1_accuracy: 0.7974 - output_1_loss: 0.5467 - output_2_accuracy: 0.8716 - output_2_loss: 0.3621\n",
      "Epoch 8/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.9435 - output_1_accuracy: 0.7994 - output_1_loss: 0.5421 - output_2_accuracy: 0.8735 - output_2_loss: 0.3577\n",
      "Epoch 8: loss improved from 0.94993 to 0.94404, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.9435 - output_1_accuracy: 0.7994 - output_1_loss: 0.5421 - output_2_accuracy: 0.8735 - output_2_loss: 0.3577\n",
      "Epoch 9/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.9421 - output_1_accuracy: 0.7993 - output_1_loss: 0.5417 - output_2_accuracy: 0.8740 - output_2_loss: 0.3565\n",
      "Epoch 9: loss improved from 0.94404 to 0.93767, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.9421 - output_1_accuracy: 0.7993 - output_1_loss: 0.5417 - output_2_accuracy: 0.8740 - output_2_loss: 0.3565\n",
      "Epoch 10/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.9343 - output_1_accuracy: 0.8018 - output_1_loss: 0.5369 - output_2_accuracy: 0.8749 - output_2_loss: 0.3533\n",
      "Epoch 10: loss improved from 0.93767 to 0.93309, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.9343 - output_1_accuracy: 0.8018 - output_1_loss: 0.5369 - output_2_accuracy: 0.8749 - output_2_loss: 0.3533\n",
      "Epoch 11/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9260 - output_1_accuracy: 0.8029 - output_1_loss: 0.5331 - output_2_accuracy: 0.8769 - output_2_loss: 0.3488\n",
      "Epoch 11: loss improved from 0.93309 to 0.92430, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.9260 - output_1_accuracy: 0.8029 - output_1_loss: 0.5331 - output_2_accuracy: 0.8769 - output_2_loss: 0.3488\n",
      "Epoch 12/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.9234 - output_1_accuracy: 0.8043 - output_1_loss: 0.5298 - output_2_accuracy: 0.8766 - output_2_loss: 0.3495\n",
      "Epoch 12: loss improved from 0.92430 to 0.92157, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.9234 - output_1_accuracy: 0.8043 - output_1_loss: 0.5298 - output_2_accuracy: 0.8766 - output_2_loss: 0.3495\n",
      "Epoch 13/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.9167 - output_1_accuracy: 0.8055 - output_1_loss: 0.5261 - output_2_accuracy: 0.8777 - output_2_loss: 0.3462\n",
      "Epoch 13: loss improved from 0.92157 to 0.91585, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.9167 - output_1_accuracy: 0.8055 - output_1_loss: 0.5261 - output_2_accuracy: 0.8777 - output_2_loss: 0.3462\n",
      "Epoch 14/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9132 - output_1_accuracy: 0.8062 - output_1_loss: 0.5254 - output_2_accuracy: 0.8789 - output_2_loss: 0.3434\n",
      "Epoch 14: loss improved from 0.91585 to 0.91446, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.9132 - output_1_accuracy: 0.8062 - output_1_loss: 0.5254 - output_2_accuracy: 0.8789 - output_2_loss: 0.3434\n",
      "Epoch 15/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.9076 - output_1_accuracy: 0.8076 - output_1_loss: 0.5207 - output_2_accuracy: 0.8788 - output_2_loss: 0.3423\n",
      "Epoch 15: loss improved from 0.91446 to 0.90777, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 46ms/step - loss: 0.9076 - output_1_accuracy: 0.8076 - output_1_loss: 0.5207 - output_2_accuracy: 0.8788 - output_2_loss: 0.3423\n",
      "Epoch 16/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.9032 - output_1_accuracy: 0.8092 - output_1_loss: 0.5169 - output_2_accuracy: 0.8796 - output_2_loss: 0.3417\n",
      "Epoch 16: loss improved from 0.90777 to 0.90318, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 47ms/step - loss: 0.9032 - output_1_accuracy: 0.8092 - output_1_loss: 0.5169 - output_2_accuracy: 0.8796 - output_2_loss: 0.3417\n",
      "Epoch 17/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.9047 - output_1_accuracy: 0.8090 - output_1_loss: 0.5191 - output_2_accuracy: 0.8797 - output_2_loss: 0.3411\n",
      "Epoch 17: loss did not improve from 0.90318\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.9047 - output_1_accuracy: 0.8090 - output_1_loss: 0.5191 - output_2_accuracy: 0.8797 - output_2_loss: 0.3411\n",
      "Epoch 18/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.8988 - output_1_accuracy: 0.8107 - output_1_loss: 0.5146 - output_2_accuracy: 0.8799 - output_2_loss: 0.3397\n",
      "Epoch 18: loss improved from 0.90318 to 0.89825, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.8988 - output_1_accuracy: 0.8107 - output_1_loss: 0.5146 - output_2_accuracy: 0.8799 - output_2_loss: 0.3397\n",
      "Epoch 19/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.8966 - output_1_accuracy: 0.8112 - output_1_loss: 0.5132 - output_2_accuracy: 0.8805 - output_2_loss: 0.3388\n",
      "Epoch 19: loss improved from 0.89825 to 0.89543, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 45ms/step - loss: 0.8966 - output_1_accuracy: 0.8112 - output_1_loss: 0.5132 - output_2_accuracy: 0.8805 - output_2_loss: 0.3388\n",
      "Epoch 20/20\n",
      "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.8938 - output_1_accuracy: 0.8117 - output_1_loss: 0.5115 - output_2_accuracy: 0.8809 - output_2_loss: 0.3375\n",
      "Epoch 20: loss improved from 0.89543 to 0.89182, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 44ms/step - loss: 0.8938 - output_1_accuracy: 0.8117 - output_1_loss: 0.5115 - output_2_accuracy: 0.8809 - output_2_loss: 0.3375\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_checkpoint.keras')\n",
    "batch_size = 1024\n",
    "\n",
    "datagen_train = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batchsize=batch_size)\n",
    "\n",
    "# Training del modello\n",
    "history = model.fit(\n",
    "    datagen_train,\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yyWmtCc8KuHx",
    "outputId": "bd82253b-6801-4c31-86c2-fd6fa2dd3329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.8550 - output_1_accuracy: 0.8181 - output_1_loss: 0.4949 - output_2_accuracy: 0.8869 - output_2_loss: 0.3221\n",
      "Epoch 1: loss improved from 0.89182 to 0.85041, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 86ms/step - loss: 0.8550 - output_1_accuracy: 0.8181 - output_1_loss: 0.4949 - output_2_accuracy: 0.8869 - output_2_loss: 0.3221\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8485 - output_1_accuracy: 0.8188 - output_1_loss: 0.4924 - output_2_accuracy: 0.8868 - output_2_loss: 0.3208\n",
      "Epoch 2: loss improved from 0.85041 to 0.84836, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 0.8485 - output_1_accuracy: 0.8188 - output_1_loss: 0.4924 - output_2_accuracy: 0.8868 - output_2_loss: 0.3208\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8479 - output_1_accuracy: 0.8192 - output_1_loss: 0.4921 - output_2_accuracy: 0.8875 - output_2_loss: 0.3197\n",
      "Epoch 3: loss improved from 0.84836 to 0.84757, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 0.8479 - output_1_accuracy: 0.8192 - output_1_loss: 0.4921 - output_2_accuracy: 0.8875 - output_2_loss: 0.3197\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8452 - output_1_accuracy: 0.8198 - output_1_loss: 0.4902 - output_2_accuracy: 0.8877 - output_2_loss: 0.3185\n",
      "Epoch 4: loss improved from 0.84757 to 0.84428, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 0.8452 - output_1_accuracy: 0.8198 - output_1_loss: 0.4902 - output_2_accuracy: 0.8877 - output_2_loss: 0.3185\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8416 - output_1_accuracy: 0.8206 - output_1_loss: 0.4877 - output_2_accuracy: 0.8882 - output_2_loss: 0.3176\n",
      "Epoch 5: loss improved from 0.84428 to 0.84115, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 0.8416 - output_1_accuracy: 0.8206 - output_1_loss: 0.4877 - output_2_accuracy: 0.8882 - output_2_loss: 0.3176\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8376 - output_1_accuracy: 0.8214 - output_1_loss: 0.4856 - output_2_accuracy: 0.8888 - output_2_loss: 0.3153\n",
      "Epoch 6: loss improved from 0.84115 to 0.83683, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 0.8376 - output_1_accuracy: 0.8214 - output_1_loss: 0.4856 - output_2_accuracy: 0.8888 - output_2_loss: 0.3153\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8346 - output_1_accuracy: 0.8225 - output_1_loss: 0.4835 - output_2_accuracy: 0.8894 - output_2_loss: 0.3145\n",
      "Epoch 7: loss improved from 0.83683 to 0.83364, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 0.8346 - output_1_accuracy: 0.8225 - output_1_loss: 0.4835 - output_2_accuracy: 0.8894 - output_2_loss: 0.3145\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8304 - output_1_accuracy: 0.8236 - output_1_loss: 0.4813 - output_2_accuracy: 0.8901 - output_2_loss: 0.3127\n",
      "Epoch 8: loss improved from 0.83364 to 0.82985, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 86ms/step - loss: 0.8304 - output_1_accuracy: 0.8236 - output_1_loss: 0.4813 - output_2_accuracy: 0.8901 - output_2_loss: 0.3127\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8281 - output_1_accuracy: 0.8242 - output_1_loss: 0.4795 - output_2_accuracy: 0.8900 - output_2_loss: 0.3118\n",
      "Epoch 9: loss improved from 0.82985 to 0.82750, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 0.8281 - output_1_accuracy: 0.8242 - output_1_loss: 0.4795 - output_2_accuracy: 0.8900 - output_2_loss: 0.3118\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8289 - output_1_accuracy: 0.8240 - output_1_loss: 0.4798 - output_2_accuracy: 0.8898 - output_2_loss: 0.3124\n",
      "Epoch 10: loss improved from 0.82750 to 0.82635, saving model to model_checkpoint.keras\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 85ms/step - loss: 0.8289 - output_1_accuracy: 0.8240 - output_1_loss: 0.4798 - output_2_accuracy: 0.8898 - output_2_loss: 0.3124\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_checkpoint.keras')\n",
    "batch_size = 2048\n",
    "\n",
    "datagen_train = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batchsize=batch_size)\n",
    "\n",
    "# Training del modello\n",
    "history = model.fit(\n",
    "    datagen_train,\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sGCKSaRIRy6P",
    "outputId": "4d5cf0cd-72b9-4b9f-b11b-50d89d95e8e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.7911 - output_1_accuracy: 0.8306 - output_1_loss: 0.4624 - output_2_accuracy: 0.8949 - output_2_loss: 0.2989\n",
      "Epoch 1: loss improved from 0.82635 to 0.78912, saving model to model_checkpoint.keras\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 172ms/step - loss: 0.7911 - output_1_accuracy: 0.8306 - output_1_loss: 0.4624 - output_2_accuracy: 0.8949 - output_2_loss: 0.2989\n",
      "Epoch 2/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.7847 - output_1_accuracy: 0.8323 - output_1_loss: 0.4582 - output_2_accuracy: 0.8957 - output_2_loss: 0.2967\n",
      "Epoch 2: loss improved from 0.78912 to 0.78206, saving model to model_checkpoint.keras\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 173ms/step - loss: 0.7847 - output_1_accuracy: 0.8323 - output_1_loss: 0.4582 - output_2_accuracy: 0.8957 - output_2_loss: 0.2967\n",
      "Epoch 3/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.7753 - output_1_accuracy: 0.8343 - output_1_loss: 0.4528 - output_2_accuracy: 0.8972 - output_2_loss: 0.2927\n",
      "Epoch 3: loss improved from 0.78206 to 0.77338, saving model to model_checkpoint.keras\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 170ms/step - loss: 0.7753 - output_1_accuracy: 0.8343 - output_1_loss: 0.4528 - output_2_accuracy: 0.8972 - output_2_loss: 0.2927\n",
      "Epoch 4/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.7676 - output_1_accuracy: 0.8361 - output_1_loss: 0.4479 - output_2_accuracy: 0.8981 - output_2_loss: 0.2897\n",
      "Epoch 4: loss improved from 0.77338 to 0.76610, saving model to model_checkpoint.keras\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 171ms/step - loss: 0.7676 - output_1_accuracy: 0.8361 - output_1_loss: 0.4479 - output_2_accuracy: 0.8981 - output_2_loss: 0.2897\n",
      "Epoch 5/5\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.7608 - output_1_accuracy: 0.8379 - output_1_loss: 0.4437 - output_2_accuracy: 0.8991 - output_2_loss: 0.2872\n",
      "Epoch 5: loss improved from 0.76610 to 0.75919, saving model to model_checkpoint.keras\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 170ms/step - loss: 0.7608 - output_1_accuracy: 0.8379 - output_1_loss: 0.4437 - output_2_accuracy: 0.8991 - output_2_loss: 0.2872\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model_checkpoint.keras')\n",
    "batch_size = 4096\n",
    "\n",
    "datagen_train = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batchsize=batch_size)\n",
    "\n",
    "# Training del modello\n",
    "history = model.fit(\n",
    "    datagen_train,\n",
    "    steps_per_epoch=3000,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IWcOjdZg7jB",
    "outputId": "e4c7e0d0-180f-4225-9763-862f3399071e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 0.7370 - output_1_accuracy: 0.8424 - output_1_loss: 0.4325 - output_2_accuracy: 0.9024 - output_2_loss: 0.2782\n",
      "Epoch 1: loss improved from 0.75919 to 0.73213, saving model to model_checkpoint.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 344ms/step - loss: 0.7370 - output_1_accuracy: 0.8425 - output_1_loss: 0.4325 - output_2_accuracy: 0.9024 - output_2_loss: 0.2782\n",
      "Epoch 2/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - loss: 0.7296 - output_1_accuracy: 0.8430 - output_1_loss: 0.4301 - output_2_accuracy: 0.9033 - output_2_loss: 0.2759\n",
      "Epoch 2: loss improved from 0.73213 to 0.72937, saving model to model_checkpoint.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 342ms/step - loss: 0.7296 - output_1_accuracy: 0.8430 - output_1_loss: 0.4301 - output_2_accuracy: 0.9033 - output_2_loss: 0.2759\n",
      "Epoch 3/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - loss: 0.7305 - output_1_accuracy: 0.8430 - output_1_loss: 0.4304 - output_2_accuracy: 0.9030 - output_2_loss: 0.2762\n",
      "Epoch 3: loss did not improve from 0.72937\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 341ms/step - loss: 0.7305 - output_1_accuracy: 0.8430 - output_1_loss: 0.4304 - output_2_accuracy: 0.9030 - output_2_loss: 0.2762\n",
      "Epoch 4/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 0.7288 - output_1_accuracy: 0.8438 - output_1_loss: 0.4285 - output_2_accuracy: 0.9031 - output_2_loss: 0.2761\n",
      "Epoch 4: loss improved from 0.72937 to 0.72914, saving model to model_checkpoint.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 344ms/step - loss: 0.7288 - output_1_accuracy: 0.8438 - output_1_loss: 0.4285 - output_2_accuracy: 0.9031 - output_2_loss: 0.2761\n",
      "Epoch 5/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - loss: 0.7296 - output_1_accuracy: 0.8438 - output_1_loss: 0.4287 - output_2_accuracy: 0.9028 - output_2_loss: 0.2767\n",
      "Epoch 5: loss did not improve from 0.72914\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 341ms/step - loss: 0.7296 - output_1_accuracy: 0.8438 - output_1_loss: 0.4287 - output_2_accuracy: 0.9028 - output_2_loss: 0.2767\n",
      "Epoch 6/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - loss: 0.7288 - output_1_accuracy: 0.8437 - output_1_loss: 0.4288 - output_2_accuracy: 0.9033 - output_2_loss: 0.2757\n",
      "Epoch 6: loss improved from 0.72914 to 0.72827, saving model to model_checkpoint.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 341ms/step - loss: 0.7288 - output_1_accuracy: 0.8437 - output_1_loss: 0.4288 - output_2_accuracy: 0.9033 - output_2_loss: 0.2757\n",
      "Epoch 7/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - loss: 0.7280 - output_1_accuracy: 0.8441 - output_1_loss: 0.4281 - output_2_accuracy: 0.9031 - output_2_loss: 0.2756\n",
      "Epoch 7: loss improved from 0.72827 to 0.72801, saving model to model_checkpoint.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 342ms/step - loss: 0.7280 - output_1_accuracy: 0.8441 - output_1_loss: 0.4281 - output_2_accuracy: 0.9031 - output_2_loss: 0.2756\n",
      "Epoch 8/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - loss: 0.7279 - output_1_accuracy: 0.8448 - output_1_loss: 0.4280 - output_2_accuracy: 0.9033 - output_2_loss: 0.2756\n",
      "Epoch 8: loss improved from 0.72801 to 0.72797, saving model to model_checkpoint.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 339ms/step - loss: 0.7279 - output_1_accuracy: 0.8448 - output_1_loss: 0.4280 - output_2_accuracy: 0.9033 - output_2_loss: 0.2756"
     ]
    }
   ],
   "source": [
    "model = load_model('model_checkpoint.keras')\n",
    "batch_size = 8192\n",
    "\n",
    "datagen_train = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batchsize=batch_size)\n",
    "\n",
    "# Training del modello\n",
    "history = model.fit(\n",
    "    datagen_train,\n",
    "    steps_per_epoch=500,\n",
    "    epochs=8,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poichè i risultati di training sembrano abbastanza soddisfacenti, ma sicuramente migliorabili, si passa alla parte di testing e valutazione modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juxxipgCG7NY"
   },
   "source": [
    "## Valutazione modello\n",
    "Valutazione del modello svolta secondo la consegna (testing su 10000 campioni ed _evaluation_ svolta per 10 volte consecutive per calcolare la _accuracy media_ e la _standard devition_), ispirandosi al file fornito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZISIOp08zFuj",
    "outputId": "8968a5c2-af51-40e1-e7c0-59eb63e7225e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 290ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Mean accuracy: 0.7689, Standard deviation: 0.0015\n"
     ]
    }
   ],
   "source": [
    "# Generatore di testing\n",
    "testgen = datagenerator(cifar10_x_test_1, cifar10_x_test_2, cifar10_y_test_1, cifar10_y_test_2, batchsize=10000)\n",
    "# Ricavo modello salvato\n",
    "model = load_model('model_checkpoint.keras')\n",
    "\n",
    "# Funzione per valutare il modello\n",
    "def eval_model(model, testgen, repeat_eval=10):\n",
    "    \"\"\"\n",
    "    Valuta il modello calcolando l'accuratezza media e la deviazione standard.\n",
    "    \"\"\"\n",
    "    eval_results = []\n",
    "    for _ in range(repeat_eval):\n",
    "        eval_samples_x, eval_samples_y = next(testgen)\n",
    "        predictions = model.predict(eval_samples_x)\n",
    "\n",
    "        correct_1 = np.argmax(predictions[0], axis=1) == np.argmax(eval_samples_y[0], axis=1)\n",
    "        correct_2 = np.argmax(predictions[1], axis=1) == np.argmax(eval_samples_y[1], axis=1)\n",
    "\n",
    "        accuracy = (np.mean(correct_1) + np.mean(correct_2)) / 2\n",
    "        eval_results.append(accuracy)\n",
    "\n",
    "    mean_accuracy = np.mean(eval_results)\n",
    "    std_deviation = np.std(eval_results)\n",
    "    return mean_accuracy, std_deviation\n",
    "\n",
    "# Valutazione del modello\n",
    "mean_acc, std_dev = eval_model(model, testgen)\n",
    "print(f\"Mean accuracy: {mean_acc:.4f}, Standard deviation: {std_dev:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptD2pHucc7O1"
   },
   "source": [
    "## Considerazioni finali e Possibili Improvement\n",
    "Come si può notare dai risultati del training effettuato, il modello tende a raggiungere un'_accuracy_ sul secondo output leggermente maggiore rispetto al primo (*output_1_accuracy*: 0.8439, *output_2_accuracy*: 0.9033) con una _loss_ generale di circa 0.72. Sicuramente con ulteriori fasi di training si potrebbe ottenere un **leggero miglioramento** di qualche punto perentuale.\n",
    "\n",
    "Come si può notare nelle ultime fasi di training, l'improvment della loss diventa sempre più bassa.\n",
    "Di conseguenza si evince che un'**ulteriore aumento rilevante delle prestazioni**, rispetto alla fase di testing (es: del 10%, e quindi passare da circa 77% a circa il 90% di _mean accuracy_ come i migliori modelli per il problema proposto), può esser dato soltanto andando a **modificare il modello stesso** ed attuando alcune accortezze sui dati generati:\n",
    "- **Data Augmentation**: aumentare la varietà del dataset introducendo trasformazioni come rotazioni, flip, scaling;\n",
    "- **Aggiunta di ulteriori layer**: avere un'architettura più profonda;\n",
    "- **Tuning del modello**: sperimentare con anche altri optimizer, ottimizzare la dimensione del batch o il tasso di dropout;\n",
    "- **Regularizzazione migliore**: applicare altre tecniche di regolarizzazione come L1/L2 o aggiungere più Dropout;\n",
    "- **Validation set**: utilizzare un set di validazione per monitorare l'overfitting durante il training (ad esempio il 20% dei dati ti training).\n",
    "\n",
    "Per quanto ne concerne la _Standard deviation_ essa è abbastanza bassa, quindi si può dire che il modello è **stabile** e **coerente**.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
